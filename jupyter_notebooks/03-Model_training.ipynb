{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Meet business requirement 2: \"The Client wants to predict if a cherry tree is healthy or is infected with powerdy mildew\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "\n",
        "-  inputs/cherry_leaves_dataset/train\n",
        "-  inputs/cherry_leaves_dataset/test\n",
        "-  inputs/cherry_leaves_dataset/validation\n",
        "-  image shape\n",
        "\n",
        "\n",
        "## Outputs\n",
        "\n",
        "\n",
        "- Images distribution plot in train, validation, and test set\n",
        "- Image augmentation\n",
        "- Class indices to change prediction inference in labels\n",
        "- Machine learning model creation and training\n",
        "- Save model\n",
        "- Learning curve plot for model performance\n",
        "- Model evaluation on pickle file\n",
        "- Prediction on the random image file\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import joblib\n",
        "import sklearn\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score\n",
        "import matplotlib as mpl\n",
        "from matplotlib.image import imread"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We are assuming you will store the notebooks in a subfolder, therefore when running the notebook in the editor, you will need to change the working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set inputs and output paths\n",
        "\n",
        "inputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/cherry_leaves_dataset/cherry-leaves'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "version = 'v2'\n",
        "\n",
        "file_path = f'outputs/{version}'\n",
        "version_file_path = os.path.join(current_dir, file_path)\n",
        "\n",
        "if os.path.exists(version_file_path):\n",
        "    print(f\"version {version} already exists. Create a new version\")\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "labels = sorted(os.listdir(train_path))\n",
        "print('Label for the images are', labels)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Confirm volume of images to data sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "folders = ['train', 'validation', 'test']\n",
        "\n",
        "df_freq = pd.DataFrame([{'Set': folder,\n",
        "                         'Label': label,\n",
        "                         'Frequency': sum(1 for _ in os.scandir(os.path.join(my_data_dir, folder, label)))}\n",
        "                        for folder in folders\n",
        "                        for label in labels])\n",
        "\n",
        "for folder in folders:\n",
        "    for label in labels:\n",
        "        print(\n",
        "            f\"* {folder} - {label}: {df_freq[(df_freq['Set'] == folder) & (df_freq['Label'] == label)]['Frequency'].values[0]} images\")\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "my_colors = ['#55A868', '#C44E52']\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency',\n",
        "            hue='Label', palette=my_colors)\n",
        "plt.savefig(f'{file_path}/labels_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Image Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "augmented_data = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    rescale=1./255\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "data_color_mode = 'rgb'\n",
        "data_class_mode = 'binary'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "train_set = augmented_data.flow_from_directory(train_path,\n",
        "                                               target_size=image_shape[:2],\n",
        "                                               color_mode=data_color_mode,\n",
        "                                               batch_size=batch_size,\n",
        "                                               class_mode=data_class_mode,\n",
        "                                               shuffle=True\n",
        "                                               )\n",
        "\n",
        "train_set.class_indices\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='binary',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='binary',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_augmented_image(label_set, display_size=3):\n",
        "    label_class = label_set.class_indices\n",
        "    for _ in range(display_size):\n",
        "        img, label = label_set.next()\n",
        "        print(img.shape)\n",
        "        img_class = list(label_class.keys())[\n",
        "            list(label_class.values()).index(label[0])]\n",
        "        plt.imshow(img[0])\n",
        "        plt.axis('off')\n",
        "        plt.title(img_class)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_augmented_image(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_augmented_image(validation_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_augmented_image(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Creating the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Import the Machine Learning package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "! pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import keras_tuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def model_builder(hp):\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=2, kernel_size=(3, 3), input_shape=image_shape,\n",
        "                     activation='relu',))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=4, kernel_size=(3, 3), input_shape=image_shape,\n",
        "                     activation='relu',))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=8, kernel_size=(3, 3), input_shape=image_shape,\n",
        "                     activation='relu',))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    hp_units = hp.Int('units', min_value=16, max_value=64, step=16)\n",
        "    model.add(Dense(units=hp_units, activation='relu',\n",
        "              kernel_regularizer=l2(0.001)))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(1, activation='tanh'))\n",
        "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
        "    opt = keras.optimizers.Adam(learning_rate=hp_learning_rate)\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "                  optimizer=opt,\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory=file_path,\n",
        "                     project_name='hypertuning'\n",
        "                     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=10,\n",
        "                     factor=3,\n",
        "                     directory=file_path,\n",
        "                     project_name='hypertuning'\n",
        "                     )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.utils import class_weight\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    'balanced',\n",
        "    np.unique(train_set.classes),\n",
        "    train_set.classes)\n",
        "\n",
        "train_class_weights = dict(enumerate(class_weights))\n",
        "train_class_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tuner.search(train_set,\n",
        "             epochs=25,\n",
        "             steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "             validation_data=validation_set,\n",
        "             class_weight=train_class_weights,\n",
        "             callbacks=[early_stop],\n",
        "             verbose=2)\n",
        "\n",
        "optimal_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(f\"\"\"\n",
        "The hyperparameter search is complete. The optimal number of units in the\n",
        "first densely-connected layer is {optimal_hps.get('units')} and the optimal\n",
        "learning rate for the optimizer is {optimal_hps.get('learning_rate')}.\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tuner.hypermodel.build(optimal_hps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(train_set,\n",
        "          epochs=20,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          class_weight=train_class_weights,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.fit(train_set,\n",
        "          epochs=20,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          class_weight=train_class_weights,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(f'{file_path}/mildew_detector_model.h5')\n",
        "print(f'{file_path}/mildew_detector_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)\n",
        "print(\"Model accuracy: {:.2f}%\".format(evaluation[1] * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation, filename=f'{file_path}/evaluation.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ROC curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "pred = model.predict(test_set)\n",
        "\n",
        "fpr, tpr, thresholds = roc_curve(test_set.classes, pred)\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(fpr, tpr, color='blue', lw=2,\n",
        "         label=f'ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='grey', lw=2,\n",
        "         linestyle='--', label='Random Guess')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate (FPR)')\n",
        "plt.ylabel('True Positive Rate (TPR)')\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.savefig(f'{file_path}/roc_curve.png', bbox_inches='tight', dpi=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "y_pred = np.round(pred).astype(int)\n",
        "\n",
        "target_names = ['Healthy', 'Powdery Mildew']\n",
        "confusion_mat = confusion_matrix(test_set.classes, y_pred)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(confusion_mat,\n",
        "            annot=True,\n",
        "            fmt='g',\n",
        "            cmap='Blues',\n",
        "            xticklabels=['Predicted Healthy', 'Predicted Powdery Mildew'],\n",
        "            yticklabels=['Actual Healthy', 'Actual Powdery Mildew'])\n",
        "plt.title('Confusion Matrix for Powdery Mildew Classification')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.savefig(f'{file_path}/confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
        "\n",
        "clf_report = classification_report(\n",
        "    test_set.classes, y_pred, target_names=target_names)\n",
        "\n",
        "print(clf_report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Classification Plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "clf_report = classification_report(\n",
        "    test_set.classes, y_pred, target_names=labels, output_dict=True)\n",
        "\n",
        "keys_to_plot = [key for key in clf_report.keys() if key not in (\n",
        "    'accuracy', 'macro avg', 'weighted avg')]\n",
        "df = pd.DataFrame(clf_report, columns=keys_to_plot).T\n",
        "df = df.sort_values(by=['support'], ascending=True)\n",
        "\n",
        "mask = np.zeros(df.shape)\n",
        "mask[:, -1] = True\n",
        "cmap = 'Greens'\n",
        "norm = mpl.colors.Normalize(vmin=df['support'].min(), vmax=df['support'].sum())\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "ax = sns.heatmap(df, mask=mask, annot=True, cmap=cmap, fmt='.3g',\n",
        "                 cbar=False, linewidths=.4, linecolor='white', vmin=0.0, vmax=1.0)\n",
        "\n",
        "mask = np.zeros(df.shape)\n",
        "mask[:, :-1] = True\n",
        "ax = sns.heatmap(df, mask=mask, annot=True, cmap=cmap, cbar=False, linewidths=2,\n",
        "                 linecolor='white', fmt='.0f', vmin=df['support'].min(), vmax=df['support'].sum(), norm=norm)\n",
        "\n",
        "plt.title('Classification Report Plot')\n",
        "if labels is not None:\n",
        "    classes = labels\n",
        "else:\n",
        "    classes = [str(i) for i in range(len(df.index))]\n",
        "plt.yticks(np.arange(len(classes))+.5, classes, rotation=0)\n",
        "\n",
        "\n",
        "plt.savefig(f'{file_path}/classification_report.png',\n",
        "            bbox_inches='tight', dpi=150)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fresh Data prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 32\n",
        "label = labels[1]  \n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Prediction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "prediction_probability = model.predict(my_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "predicted_class = target_map[prediction_probability > 0.5]\n",
        "if predicted_class == target_map[0]:\n",
        "    prediction_probability = 1 - prediction_probability\n",
        "\n",
        "print(f'Prediction probability: {round(prediction_probability*100, 2)}%')\n",
        "print(f'Predicted class: {predicted_class}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
